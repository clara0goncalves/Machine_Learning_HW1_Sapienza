{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install Dependecies"
      ],
      "metadata": {
        "id": "uYkosDKjN6-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "bA3-dNGdN6VD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974181c0-2180-4fa0-df6d-6d4a64a65d31"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set device to GPU if is available otherwise set device as cpu**"
      ],
      "metadata": {
        "id": "83S06ig1RMKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check if GPU is available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "1IX6jLICPN4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e23692-fad2-491d-84a9-35d2497aa0e4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "BaBjTEuIRHsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.base import BaseEstimator, RegressorMixin"
      ],
      "metadata": {
        "id": "7jsLAS7jRJ2-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Dataset##\n",
        "\n",
        "- The Datatset used in this project was generated using the Mujoco simulator with three different configurations:\n",
        "- 2D (2 joints)\n",
        "- 2D (3 joints)\n",
        "- 3D (5 joints)\n",
        "\n",
        "The format of the data is in CSV format, including information about Joint angles, fingertip position, and orientation.\n"
      ],
      "metadata": {
        "id": "hIO0AeMWIExL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1. Visualise data from the simulator"
      ],
      "metadata": {
        "id": "0_uqRtyhJDj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler2.csv"
      ],
      "metadata": {
        "id": "6VflkHGKJDRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "048b5267-e751-4fb6-8a67-aeeb5da1f35d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j0;j1;cos(j0);cos(j1);sin(j0);sin(j1);ft_x;ft_y;ft_qw;ft_qz\n",
            " 0.055; -0.012;  0.998;  1.000;  0.055; -0.012;  0.210;  0.010;  1.000;  0.021\n",
            " 0.076; -0.017;  0.997;  1.000;  0.076; -0.017;  0.210;  0.014;  1.000;  0.030\n",
            " 0.148; -0.011;  0.989;  1.000;  0.147; -0.011;  0.208;  0.030;  0.998;  0.068\n",
            " 0.214;  0.048;  0.977;  0.999;  0.212;  0.048;  0.204;  0.050;  0.991;  0.131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler3.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNgZg0OJNaVV",
        "outputId": "452a692f-3de3-4689-e43b-873495805c28"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'logfiler3.csv' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler5.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm_lpt6_Nc-X",
        "outputId": "5ecbef36-fb82-4e42-e30e-3842dff2f658"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'logfiler5.csv' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. Preprocess the data\n"
      ],
      "metadata": {
        "id": "rbfjJsgxJI80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2R Robot"
      ],
      "metadata": {
        "id": "aCM-EXuFQxkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "dJxB_FilEapT"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('logfiler2.csv', delimiter=';')\n",
        "\n",
        "# Preprocessing: Extract inputs (joint angles and their trigonometric functions) and outputs (fingertip positions and quaternions)\n",
        "X = data[['j0', 'j1']].values\n",
        "y = data[['ft_x', 'ft_y']].values\n",
        "\n",
        "# Normalize input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Split the data into training and testing sets"
      ],
      "metadata": {
        "id": "a_UHnh5KJX6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training, validation, and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "jze3VIDOQ_aq"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Train Forward Kinematics Models##\n",
        "\n"
      ],
      "metadata": {
        "id": "gcdL1pWYJNsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Robot 2R"
      ],
      "metadata": {
        "id": "LIaJ6J5pOJey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the architecture of the model (Feedforward Neural Network) to learn forward kinematics.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1yDUGGEzJSao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "class ForwardKinematicsModel(nn.Module):\n",
        "    def __init__(self, hidden_size=hidden_size, dropout_rate=0.3):\n",
        "        super(ForwardKinematicsModel, self).__init__()\n",
        "        # Define a feedforward network with configurable hidden_size and dropout\n",
        "        self.fc1 = nn.Linear(2, hidden_size)  # Input layer\n",
        "        self.dropout1 = nn.Dropout(p=dropout_rate)    # Dropout after first hidden layer\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Second hidden layer\n",
        "        self.dropout2 = nn.Dropout(p=dropout_rate)    # Dropout after second hidden layer\n",
        "        self.fc3 = nn.Linear(hidden_size, 2)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)  # Apply dropout after first hidden layer\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)  # Apply dropout after second hidden layer\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "model = ForwardKinematicsModel()"
      ],
      "metadata": {
        "id": "pwmiwxseZOMX"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hyperparameter Search"
      ],
      "metadata": {
        "id": "mvZc8OBWPvSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Grid Search"
      ],
      "metadata": {
        "id": "kEHlC7SSNV8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Regressor Wrapper\n",
        "class PyTorchRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, hidden_size=hidden_size  , lr=learning_rate, epochs=num_epochs):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.model = ForwardKinematicsModel(hidden_size=self.hidden_size)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_train = torch.tensor(X, dtype=torch.float32)\n",
        "        y_train = torch.tensor(y, dtype=torch.float32)\n",
        "        for epoch in range(self.epochs):\n",
        "            self.model.train()\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(X_train)\n",
        "            loss = self.criterion(output, y_train)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_test = torch.tensor(X, dtype=torch.float32)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X_test)\n",
        "        return predictions.numpy()\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('logfiler2.csv', sep=';')\n",
        "X = df[['j0', 'j1']].values\n",
        "y = df[['ft_x', 'ft_y']].values\n",
        "\n",
        "# Split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up hyperparameters to search\n",
        "param_grid = {\n",
        "    'hidden_size': [32, 64, 128],  # Try different numbers of hidden units\n",
        "    'lr': [0.001, 0.01],           # Try different learning rates\n",
        "    'epochs': [100, 200],          # Try different numbers of epochs\n",
        "}\n",
        "\n",
        "# Instantiate the model wrapper\n",
        "pytorch_model = PyTorchRegressor()\n",
        "\n",
        "# Use GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=pytorch_model, param_grid=param_grid, cv=3, verbose=2, n_jobs=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best two combinations of hyperparameters\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "results = results.sort_values(by='mean_test_score', ascending=False)\n",
        "\n",
        "# Print the best and second-best hyperparameters\n",
        "print(\"Best combination of hyperparameters:\")\n",
        "print(results.iloc[0][['param_hidden_size', 'param_lr', 'param_epochs', 'mean_test_score']])\n",
        "print(\"\\nSecond-best combination of hyperparameters:\")\n",
        "print(results.iloc[1][['param_hidden_size', 'param_lr', 'param_epochs', 'mean_test_score']])\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_loss = mean_squared_error(y_test, y_pred)\n",
        "print(f\"\\nTest MSE of the best model: {test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "Rn7gU9ofNU9l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5835453-a29b-42b9-a76d-b217cf1590ce"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "[CV] END ...............epochs=100, hidden_size=32, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=32, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=32, lr=0.001; total time=   0.0s\n",
            "[CV] END ................epochs=100, hidden_size=32, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=100, hidden_size=32, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=100, hidden_size=32, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ..............epochs=100, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ..............epochs=100, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ..............epochs=100, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=32, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=32, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=32, lr=0.001; total time=   0.0s\n",
            "[CV] END ................epochs=200, hidden_size=32, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=200, hidden_size=32, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=200, hidden_size=32, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ..............epochs=200, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ..............epochs=200, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ..............epochs=200, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=128, lr=0.01; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 36 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"<ipython-input-93-1abad65d442c>\", line 17, in fit\n    output = self.model(X_train)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"<ipython-input-92-b4ecd9874a06>\", line 16, in forward\n    x = torch.relu(self.fc1(x))\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (53333x2 and 6x32)\n\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"<ipython-input-93-1abad65d442c>\", line 17, in fit\n    output = self.model(X_train)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"<ipython-input-92-b4ecd9874a06>\", line 16, in forward\n    x = torch.relu(self.fc1(x))\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (53334x2 and 6x32)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-1abad65d442c>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Use GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpytorch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Get the best two combinations of hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    994\u001b[0m                     )\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             )\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 36 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"<ipython-input-93-1abad65d442c>\", line 17, in fit\n    output = self.model(X_train)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"<ipython-input-92-b4ecd9874a06>\", line 16, in forward\n    x = torch.relu(self.fc1(x))\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (53333x2 and 6x32)\n\n--------------------------------------------------------------------------------\n12 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"<ipython-input-93-1abad65d442c>\", line 17, in fit\n    output = self.model(X_train)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"<ipython-input-92-b4ecd9874a06>\", line 16, in forward\n    x = torch.relu(self.fc1(x))\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (53334x2 and 6x32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train the models on joint angle inputs to predict fingertip positions."
      ],
      "metadata": {
        "id": "tDBMT_K2PiS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 200"
      ],
      "metadata": {
        "id": "fz1ipjrTwD-y"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the loss function and optimizer"
      ],
      "metadata": {
        "id": "Tio9LYtzPKFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "j8l_q3FnzxFk"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors only if necessary\n",
        "X_train = X_train.clone().detach().float() if isinstance(X_train, torch.Tensor) else torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = y_train.clone().detach().float() if isinstance(y_train, torch.Tensor) else torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = X_val.clone().detach().float() if isinstance(X_val, torch.Tensor) else torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = y_val.clone().detach().float() if isinstance(y_val, torch.Tensor) else torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = X_test.clone().detach().float() if isinstance(X_test, torch.Tensor) else torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = y_test.clone().detach().float() if isinstance(y_test, torch.Tensor) else torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "szvcvhW6ylGh"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables for early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "no_improvement_epochs = 0\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs, y_val)\n",
        "\n",
        "            # Calculate additional metrics\n",
        "            mae = mean_absolute_error(y_val.numpy(), val_outputs.numpy())\n",
        "            r2 = r2_score(y_val.numpy(), val_outputs.numpy())\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "                  f\"Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, \"\n",
        "                  f\"MAE: {mae:.4f}, R^2: {r2:.4f}\")\n",
        "\n",
        "            # Early stopping check\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                no_improvement_epochs = 0\n",
        "            else:\n",
        "                no_improvement_epochs += 1\n",
        "\n",
        "            if no_improvement_epochs >= patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}. Best Val Loss: {best_val_loss:.4f}\")\n",
        "                break\n",
        "\n",
        "        model.train()  # Switch back to training mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxXXl4lG5FQh",
        "outputId": "36ac94e3-b424-4a0e-93ba-3fa2daeb876b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/200], Train Loss: 0.0423, Val Loss: 0.0150, MAE: 0.0990, R^2: -0.8441\n",
            "Epoch [20/200], Train Loss: 0.0293, Val Loss: 0.0135, MAE: 0.0941, R^2: -0.6527\n",
            "Epoch [30/200], Train Loss: 0.0219, Val Loss: 0.0127, MAE: 0.0914, R^2: -0.5391\n",
            "Epoch [40/200], Train Loss: 0.0174, Val Loss: 0.0116, MAE: 0.0868, R^2: -0.4016\n",
            "Epoch [50/200], Train Loss: 0.0147, Val Loss: 0.0107, MAE: 0.0833, R^2: -0.3005\n",
            "Epoch [60/200], Train Loss: 0.0127, Val Loss: 0.0100, MAE: 0.0807, R^2: -0.2173\n",
            "Epoch [70/200], Train Loss: 0.0113, Val Loss: 0.0094, MAE: 0.0781, R^2: -0.1359\n",
            "Epoch [80/200], Train Loss: 0.0102, Val Loss: 0.0088, MAE: 0.0755, R^2: -0.0622\n",
            "Epoch [90/200], Train Loss: 0.0094, Val Loss: 0.0082, MAE: 0.0728, R^2: 0.0038\n",
            "Epoch [100/200], Train Loss: 0.0087, Val Loss: 0.0078, MAE: 0.0705, R^2: 0.0548\n",
            "Epoch [110/200], Train Loss: 0.0082, Val Loss: 0.0075, MAE: 0.0686, R^2: 0.0939\n",
            "Epoch [120/200], Train Loss: 0.0077, Val Loss: 0.0072, MAE: 0.0670, R^2: 0.1246\n",
            "Epoch [130/200], Train Loss: 0.0074, Val Loss: 0.0070, MAE: 0.0659, R^2: 0.1483\n",
            "Epoch [140/200], Train Loss: 0.0071, Val Loss: 0.0069, MAE: 0.0651, R^2: 0.1623\n",
            "Epoch [150/200], Train Loss: 0.0068, Val Loss: 0.0068, MAE: 0.0645, R^2: 0.1733\n",
            "Epoch [160/200], Train Loss: 0.0066, Val Loss: 0.0068, MAE: 0.0642, R^2: 0.1793\n",
            "Epoch [170/200], Train Loss: 0.0064, Val Loss: 0.0068, MAE: 0.0640, R^2: 0.1817\n",
            "Epoch [180/200], Train Loss: 0.0062, Val Loss: 0.0068, MAE: 0.0638, R^2: 0.1858\n",
            "Epoch [190/200], Train Loss: 0.0060, Val Loss: 0.0068, MAE: 0.0638, R^2: 0.1863\n",
            "Epoch [200/200], Train Loss: 0.0059, Val Loss: 0.0068, MAE: 0.0640, R^2: 0.1839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, y_test)\n",
        "    mae_test = mean_absolute_error(y_test.numpy(), test_outputs.numpy())\n",
        "    r2_test = r2_score(y_test.numpy(), test_outputs.numpy())\n",
        "\n",
        "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "    print(f\"Test MAE: {mae_test:.4f}\")\n",
        "    print(f\"Test R^2: {r2_test:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXuwFfNlkmEQ",
        "outputId": "ad419ebf-1722-4bfe-aa58-6688ae002326"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0041\n",
            "Test MAE: 0.0505\n",
            "Test R^2: 0.5014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Compare Jacobians##\n"
      ],
      "metadata": {
        "id": "lWNe5FjVJolV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3.1. Compute the Jacobian matrix for the learned forward kinematics using automatic differentiation.\n",
        "\n"
      ],
      "metadata": {
        "id": "xTzh1e1BJu3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data (replace this with your actual dataset loading method)\n",
        "df = pd.read_csv('logfiler2.csv', sep=';')\n",
        "X = df[['j0', 'j1']].values  # Joint angles\n",
        "y = df[['ft_x', 'ft_y']].values  # Fingertip positions\n",
        "\n",
        "# Convert to torch tensor\n",
        "X_test = torch.tensor(X, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "vWgtFZP5OCJi"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Assuming X_test is a tensor and you want to extract the first sample\n",
        "X_test_sample = X_test[0].clone().detach().unsqueeze(0).float()  # Add batch dimension and detach\n",
        "print(X_test_sample)"
      ],
      "metadata": {
        "id": "wXM9zpl2OMPJ",
        "outputId": "38cd9c6f-faf8-4ae9-84ec-d75e36e55d89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0550, -0.0120]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def FK(model, theta):\n",
        "    # Reshape to batch size 1 (equivalent to tf.reshape)\n",
        "    t = theta.reshape(1, 2)\n",
        "\n",
        "    # Pass through the model\n",
        "    out = model(t)\n",
        "\n",
        "    # Reshape the output to a 1D vector (equivalent to tf.reshape)\n",
        "    out = out.reshape(2,)\n",
        "\n",
        "    return out\n",
        "\n",
        "def FK_Jacobian(model, x):\n",
        "    # Ensure x requires gradients for gradient computation\n",
        "    x = x.requires_grad_(True)\n",
        "\n",
        "    # Forward pass to get y from FK\n",
        "    y = FK(model, x)\n",
        "\n",
        "    # Initialize an empty list to store Jacobian columns\n",
        "    jacobian = []\n",
        "\n",
        "    # Compute the gradient of each component of y with respect to x\n",
        "    for i in range(y.shape[0]):\n",
        "        # Gradient of y[i] with respect to x\n",
        "        grad_y = torch.autograd.grad(y[i], x, retain_graph=True, create_graph=True)[0]\n",
        "        jacobian.append(grad_y)\n",
        "\n",
        "    # Stack the Jacobian columns to form the Jacobian matrix\n",
        "    jacobian_matrix = torch.stack(jacobian, dim=0).squeeze()\n",
        "\n",
        "    return jacobian_matrix"
      ],
      "metadata": {
        "id": "JaqUqGm_C2xE"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2. Compare the computed Jacobian with the analytical Jacobian for the 2-joint robot."
      ],
      "metadata": {
        "id": "rcFxsQjkJx1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Analytical Jacobian for a 2-DOF robot\n",
        "def analytical_jacobian_from_test(data):\n",
        "    # Extract joint angles from data\n",
        "    j0 = data[0]  # j0\n",
        "    j1 = data[1]  # j1\n",
        "\n",
        "    l1 = 1.0  # Link 1 length\n",
        "    l2 = 1.0  # Link 2 length\n",
        "\n",
        "    # Calculate the Jacobian elements using the analytical formula\n",
        "    J = np.array([\n",
        "        [-l1 * np.sin(j0) - l2 * np.sin(j0 + j1), -l2 * np.sin(j0 + j1)],\n",
        "        [l1 * np.cos(j0) + l2 * np.cos(j0 + j1), l2 * np.cos(j0 + j1)]\n",
        "    ])\n",
        "    return J"
      ],
      "metadata": {
        "id": "ZwQ2k3qMJ2Jp"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Numerical Jacobian (calculated by FK_Jacobian)\n",
        "X_test_sample = X_test[0].unsqueeze(0).clone().detach().float()\n",
        "jacobian_numerical = FK_Jacobian(model, X_test_sample)\n",
        "\n",
        "# Analytical Jacobian (calculated using analytical formula)\n",
        "X_test_data = X_test[0].numpy()  # Extract joint angles for comparison\n",
        "J_analytical = analytical_jacobian_from_test(X_test_data)\n",
        "\n",
        "# Print both Jacobians\n",
        "print(\"Numerical Jacobian (PyTorch):\\n\", jacobian_numerical)\n",
        "print(\"Analytical Jacobian (2-DOF Robot):\\n\", J_analytical)\n",
        "\n",
        "# Compare both Jacobians by calculating the difference\n",
        "jacobian_difference = (jacobian_numerical.detach().numpy() - J_analytical)\n",
        "print(\"Difference between Numerical and Analytical Jacobians:\\n\", jacobian_difference)"
      ],
      "metadata": {
        "id": "uopqI4FVOPVR",
        "outputId": "eb477e38-59dc-4d4a-a25c-73e29483a6d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical Jacobian (PyTorch):\n",
            " tensor([[-0.0023,  0.0118],\n",
            "        [ 0.0407,  0.0241]], grad_fn=<SqueezeBackward0>)\n",
            "Analytical Jacobian (2-DOF Robot):\n",
            " [[-0.09795902 -0.04298675]\n",
            " [ 1.99756354  0.99907565]]\n",
            "Difference between Numerical and Analytical Jacobians:\n",
            " [[ 0.09568931  0.05483213]\n",
            " [-1.95689448 -0.97500462]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OcXMDYgJb2Dw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}