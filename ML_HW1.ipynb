{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install Dependecies"
      ],
      "metadata": {
        "id": "uYkosDKjN6-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "bA3-dNGdN6VD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfbb14e-c01a-48c4-8cd0-68b4c13d2c33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting sympy (from torch)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx (from torch)\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (3.1.2)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m381.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch)\n",
            "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filelock-3.16.1 fsspec-2024.10.0 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0 typing-extensions-4.12.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set device to GPU if is available otherwise set device as cpu**"
      ],
      "metadata": {
        "id": "83S06ig1RMKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check if GPU is available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "1IX6jLICPN4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfbe6b5a-e813-43ea-f6e7-49a574669e09"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "BaBjTEuIRHsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.base import BaseEstimator, RegressorMixin"
      ],
      "metadata": {
        "id": "7jsLAS7jRJ2-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Dataset##\n",
        "\n",
        "- The Datatset used in this project was generated using the Mujoco simulator with three different configurations:\n",
        "- 2D (2 joints)\n",
        "- 2D (3 joints)\n",
        "- 3D (5 joints)\n",
        "\n",
        "The format of the data is in CSV format, including information about Joint angles, fingertip position, and orientation.\n"
      ],
      "metadata": {
        "id": "hIO0AeMWIExL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1. Visualise data from the simulator"
      ],
      "metadata": {
        "id": "0_uqRtyhJDj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler2.csv"
      ],
      "metadata": {
        "id": "6VflkHGKJDRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2e905e-8fce-4afb-8097-84f371038339"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j0;j1;cos(j0);cos(j1);sin(j0);sin(j1);ft_x;ft_y;ft_qw;ft_qz\r\n",
            " 0.055; -0.012;  0.998;  1.000;  0.055; -0.012;  0.210;  0.010;  1.000;  0.021\r\n",
            " 0.076; -0.017;  0.997;  1.000;  0.076; -0.017;  0.210;  0.014;  1.000;  0.030\r\n",
            " 0.148; -0.011;  0.989;  1.000;  0.147; -0.011;  0.208;  0.030;  0.998;  0.068\r\n",
            " 0.214;  0.048;  0.977;  0.999;  0.212;  0.048;  0.204;  0.050;  0.991;  0.131\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler3.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNgZg0OJNaVV",
        "outputId": "ff24ddc0-a8af-4804-e97c-a0add4288be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j0;j1;j2;cos(j0);cos(j1);cos(j2);sin(j0);sin(j1);sin(j2);ft_x;ft_y;ft_qw;ft_qz\r\n",
            " 0.055; -0.012;  0.072;  0.998;  1.000;  0.997;  0.055; -0.012;  0.072;  0.309;  0.022;  0.998;  0.057\r\n",
            " 0.076; -0.017;  0.100;  0.997;  1.000;  0.995;  0.076; -0.017;  0.100;  0.308;  0.031;  0.997;  0.080\r\n",
            " 0.135; -0.059;  0.194;  0.991;  0.998;  0.981;  0.135; -0.059;  0.193;  0.305;  0.050;  0.991;  0.135\r\n",
            " 0.228; -0.110;  0.295;  0.974;  0.994;  0.957;  0.226; -0.109;  0.290;  0.297;  0.079;  0.979;  0.205\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler5.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm_lpt6_Nc-X",
        "outputId": "c35fef0c-66e5-4c1a-ee7e-db3d1cb989b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j0;j1;j2;j3;j4;cos(j0);cos(j1);cos(j2);cos(j3);cos(j4);sin(j0);sin(j1);sin(j2);sin(j3);sin(j4);ft_x;ft_y;ft_z;ft_qw;ft_qx;ft_qy;ft_qz\r\n",
            " 0.000;  0.000;  0.000;  0.000;  0.000;  1.000;  1.000;  1.000;  1.000;  1.000;  0.000;  0.000;  0.000;  0.000;  0.000;  0.000;  0.000;  0.590;  1.000;  0.000;  0.000;  0.000\r\n",
            " 0.022; -0.005;  0.028;  0.016; -0.032;  1.000;  1.000;  1.000;  1.000;  0.999;  0.022; -0.005;  0.028;  0.016; -0.032;  0.011;  0.004;  0.590;  1.000; -0.016;  0.019;  0.011\r\n",
            " 0.103;  0.005;  0.107;  0.017; -0.100;  0.995;  1.000;  0.994;  1.000;  0.995;  0.102;  0.005;  0.106;  0.017; -0.099;  0.041;  0.016;  0.587;  0.995; -0.053;  0.061;  0.054\r\n",
            " 0.209;  0.067;  0.216;  0.013; -0.174;  0.978;  0.998;  0.977;  1.000;  0.985;  0.208;  0.067;  0.215;  0.013; -0.173;  0.100;  0.042;  0.573;  0.979; -0.101;  0.138;  0.116\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. Preprocess the data\n"
      ],
      "metadata": {
        "id": "rbfjJsgxJI80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2R Robot"
      ],
      "metadata": {
        "id": "aCM-EXuFQxkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dJxB_FilEapT"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('logfiler2.csv', delimiter=';')\n",
        "\n",
        "# Preprocessing: Extract inputs (joint angles and their trigonometric functions) and outputs (fingertip positions and quaternions)\n",
        "X = data[['j0', 'j1', 'cos(j0)', 'cos(j1)', 'sin(j0)', 'sin(j1)']].values\n",
        "y = data[['ft_x', 'ft_y', 'ft_qw', 'ft_qz']].values\n",
        "\n",
        "# Normalize input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Split the data into training and testing sets"
      ],
      "metadata": {
        "id": "a_UHnh5KJX6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training, validation, and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "jze3VIDOQ_aq"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Train Forward Kinematics Models##\n",
        "\n"
      ],
      "metadata": {
        "id": "gcdL1pWYJNsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Robot 2R"
      ],
      "metadata": {
        "id": "LIaJ6J5pOJey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the architecture of the model (Feedforward Neural Network) to learn forward kinematics.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1yDUGGEzJSao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the loss function and optimizer"
      ],
      "metadata": {
        "id": "Tio9LYtzPKFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Neural Network model with Dropout\n",
        "class ForwardKinematicsModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ForwardKinematicsModel, self).__init__()\n",
        "        # Define a simple feedforward network with 2 hidden layers and Dropout\n",
        "        self.fc1 = nn.Linear(6, 64)  # Input layer (6 features)\n",
        "        self.dropout1 = nn.Dropout(p=0.3)  # Dropout with 30% probability after first hidden layer\n",
        "        self.fc2 = nn.Linear(64, 64)       # Hidden layer\n",
        "        self.dropout2 = nn.Dropout(p=0.3)  # Dropout with 30% probability after second hidden layer\n",
        "        self.fc3 = nn.Linear(64, 4)        # Output layer (4 outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)  # Apply dropout after first hidden layer\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)  # Apply dropout after second hidden layer\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cxTQNHySMQM1"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hyperparameter Search"
      ],
      "metadata": {
        "id": "mvZc8OBWPvSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Grid Search"
      ],
      "metadata": {
        "id": "kEHlC7SSNV8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrapper class for PyTorch model to use with scikit-learn GridSearchCV\n",
        "class PyTorchRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, hidden_size=hidden_size, lr=learning_rate, epochs=100):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.model = ForwardKinematicsModel(hidden_size=self.hidden_size)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Convert data to torch tensors\n",
        "        X_train = torch.tensor(X, dtype=torch.float32)\n",
        "        y_train = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(self.epochs):\n",
        "            self.model.train()\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(X_train)\n",
        "            loss = self.criterion(output, y_train)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Convert data to torch tensor and return predictions\n",
        "        X_test = torch.tensor(X, dtype=torch.float32)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X_test)\n",
        "        return predictions.numpy()\n",
        "\n",
        "# Load your dataset (replace this with your actual dataset)\n",
        "df = pd.read_csv('logfiler2.csv', sep=';')\n",
        "X = df[['j0', 'j1', 'cos(j0)', 'cos(j1)', 'sin(j0)', 'sin(j1)']].values  # Joint angles\n",
        "y = df[['ft_x', 'ft_y', 'ft_qw', 'ft_qz']].values  # Fingertip positions\n",
        "\n",
        "# Split dataset into training and test sets (80/20 split)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up hyperparameters to search\n",
        "param_grid = {\n",
        "    'hidden_size': [16, 32, 64],       # Number of hidden units in the hidden layers\n",
        "    'lr': [0.001, 0.01],            # Learning rates\n",
        "    'epochs': [100, 200, 500],           # Number of epochs to train\n",
        "}\n",
        "\n",
        "# Instantiate the PyTorch model wrapper for GridSearchCV\n",
        "pytorch_model = PyTorchRegressor()\n",
        "\n",
        "# Use GridSearchCV with the model wrapper\n",
        "grid_search = GridSearchCV(estimator=pytorch_model, param_grid=param_grid, cv=3, verbose=2, n_jobs=1)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_loss = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Test MSE: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "Rn7gU9ofNU9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183b4899-c98e-45e6-b223-52edad1f449c"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
            "[CV] END ...............epochs=100, hidden_size=16, lr=0.001; total time=   3.0s\n",
            "[CV] END ...............epochs=100, hidden_size=16, lr=0.001; total time=   3.6s\n",
            "[CV] END ...............epochs=100, hidden_size=16, lr=0.001; total time=   3.0s\n",
            "[CV] END ................epochs=100, hidden_size=16, lr=0.01; total time=   2.8s\n",
            "[CV] END ................epochs=100, hidden_size=16, lr=0.01; total time=   2.7s\n",
            "[CV] END ................epochs=100, hidden_size=16, lr=0.01; total time=   2.3s\n",
            "[CV] END ...............epochs=100, hidden_size=32, lr=0.001; total time=   2.3s\n",
            "[CV] END ...............epochs=100, hidden_size=32, lr=0.001; total time=   2.1s\n",
            "[CV] END ...............epochs=100, hidden_size=32, lr=0.001; total time=   2.2s\n",
            "[CV] END ................epochs=100, hidden_size=32, lr=0.01; total time=   2.2s\n",
            "[CV] END ................epochs=100, hidden_size=32, lr=0.01; total time=   2.2s\n",
            "[CV] END ................epochs=100, hidden_size=32, lr=0.01; total time=   2.2s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   2.2s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   2.2s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   2.2s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   2.8s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   3.2s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   3.3s\n",
            "[CV] END ...............epochs=200, hidden_size=16, lr=0.001; total time=   5.6s\n",
            "[CV] END ...............epochs=200, hidden_size=16, lr=0.001; total time=   5.8s\n",
            "[CV] END ...............epochs=200, hidden_size=16, lr=0.001; total time=   5.8s\n",
            "[CV] END ................epochs=200, hidden_size=16, lr=0.01; total time=   6.0s\n",
            "[CV] END ................epochs=200, hidden_size=16, lr=0.01; total time=   6.3s\n",
            "[CV] END ................epochs=200, hidden_size=16, lr=0.01; total time=   6.0s\n",
            "[CV] END ...............epochs=200, hidden_size=32, lr=0.001; total time=   6.1s\n",
            "[CV] END ...............epochs=200, hidden_size=32, lr=0.001; total time=   6.3s\n",
            "[CV] END ...............epochs=200, hidden_size=32, lr=0.001; total time=   5.7s\n",
            "[CV] END ................epochs=200, hidden_size=32, lr=0.01; total time=   5.5s\n",
            "[CV] END ................epochs=200, hidden_size=32, lr=0.01; total time=   6.0s\n",
            "[CV] END ................epochs=200, hidden_size=32, lr=0.01; total time=   5.9s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   5.2s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   5.8s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   5.9s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   5.7s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   5.3s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   5.3s\n",
            "[CV] END ...............epochs=500, hidden_size=16, lr=0.001; total time=  13.4s\n",
            "[CV] END ...............epochs=500, hidden_size=16, lr=0.001; total time=  12.6s\n",
            "[CV] END ...............epochs=500, hidden_size=16, lr=0.001; total time=  14.5s\n",
            "[CV] END ................epochs=500, hidden_size=16, lr=0.01; total time=  13.9s\n",
            "[CV] END ................epochs=500, hidden_size=16, lr=0.01; total time=  14.0s\n",
            "[CV] END ................epochs=500, hidden_size=16, lr=0.01; total time=  14.1s\n",
            "[CV] END ...............epochs=500, hidden_size=32, lr=0.001; total time=  13.4s\n",
            "[CV] END ...............epochs=500, hidden_size=32, lr=0.001; total time=  13.3s\n",
            "[CV] END ...............epochs=500, hidden_size=32, lr=0.001; total time=  13.7s\n",
            "[CV] END ................epochs=500, hidden_size=32, lr=0.01; total time=  13.5s\n",
            "[CV] END ................epochs=500, hidden_size=32, lr=0.01; total time=  14.5s\n",
            "[CV] END ................epochs=500, hidden_size=32, lr=0.01; total time=  13.0s\n",
            "[CV] END ...............epochs=500, hidden_size=64, lr=0.001; total time=  12.1s\n",
            "[CV] END ...............epochs=500, hidden_size=64, lr=0.001; total time=  12.7s\n",
            "[CV] END ...............epochs=500, hidden_size=64, lr=0.001; total time=  12.8s\n",
            "[CV] END ................epochs=500, hidden_size=64, lr=0.01; total time=  12.8s\n",
            "[CV] END ................epochs=500, hidden_size=64, lr=0.01; total time=  13.6s\n",
            "[CV] END ................epochs=500, hidden_size=64, lr=0.01; total time=  14.4s\n",
            "Best Hyperparameters: {'epochs': 500, 'hidden_size': 32, 'lr': 0.001}\n",
            "Test MSE: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train the models on joint angle inputs to predict fingertip positions."
      ],
      "metadata": {
        "id": "tDBMT_K2PiS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 500\n",
        "learning_rate = 0.001\n",
        "hidden_size = 64\n",
        "\n",
        "# Initialize the model\n",
        "model = ForwardKinematicsModel()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "fz1ipjrTwD-y"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors only if necessary\n",
        "X_train = X_train.clone().detach().float() if isinstance(X_train, torch.Tensor) else torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = y_train.clone().detach().float() if isinstance(y_train, torch.Tensor) else torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = X_val.clone().detach().float() if isinstance(X_val, torch.Tensor) else torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = y_val.clone().detach().float() if isinstance(y_val, torch.Tensor) else torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = X_test.clone().detach().float() if isinstance(X_test, torch.Tensor) else torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = y_test.clone().detach().float() if isinstance(y_test, torch.Tensor) else torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "szvcvhW6ylGh"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables for early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "no_improvement_epochs = 0\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs, y_val)\n",
        "\n",
        "            # Calculate additional metrics\n",
        "            mae = mean_absolute_error(y_val.numpy(), val_outputs.numpy())\n",
        "            r2 = r2_score(y_val.numpy(), val_outputs.numpy())\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "                  f\"Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, \"\n",
        "                  f\"MAE: {mae:.4f}, R^2: {r2:.4f}\")\n",
        "\n",
        "            # Early stopping check\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                no_improvement_epochs = 0\n",
        "            else:\n",
        "                no_improvement_epochs += 1\n",
        "\n",
        "            if no_improvement_epochs >= patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}. Best Val Loss: {best_val_loss:.4f}\")\n",
        "                break\n",
        "\n",
        "        model.train()  # Switch back to training mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxXXl4lG5FQh",
        "outputId": "78505cde-8d60-4cfb-830e-9f69bccc63ea"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/500], Train Loss: 0.0001, Val Loss: 0.0655, MAE: 0.1699, R^2: 0.6697\n",
            "Epoch [20/500], Train Loss: 0.0001, Val Loss: 0.0656, MAE: 0.1700, R^2: 0.6696\n",
            "Epoch [30/500], Train Loss: 0.0001, Val Loss: 0.0656, MAE: 0.1700, R^2: 0.6695\n",
            "Epoch [40/500], Train Loss: 0.0001, Val Loss: 0.0656, MAE: 0.1700, R^2: 0.6695\n",
            "Epoch [50/500], Train Loss: 0.0001, Val Loss: 0.0656, MAE: 0.1701, R^2: 0.6694\n",
            "Epoch [60/500], Train Loss: 0.0001, Val Loss: 0.0656, MAE: 0.1701, R^2: 0.6694\n",
            "Early stopping triggered at epoch 60. Best Val Loss: 0.0655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, y_test)\n",
        "    mae_test = mean_absolute_error(y_test.numpy(), test_outputs.numpy())\n",
        "    r2_test = r2_score(y_test.numpy(), test_outputs.numpy())\n",
        "\n",
        "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "    print(f\"Test MAE: {mae_test:.4f}\")\n",
        "    print(f\"Test R^2: {r2_test:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXuwFfNlkmEQ",
        "outputId": "6dd9e65c-1cab-49d8-a0c6-046b09e80231"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0001\n",
            "Test MAE: 0.0076\n",
            "Test R^2: 0.9969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Compare Jacobians##\n"
      ],
      "metadata": {
        "id": "lWNe5FjVJolV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3.1. Compute the Jacobian matrix for the learned forward kinematics using automatic differentiation.\n",
        "\n"
      ],
      "metadata": {
        "id": "xTzh1e1BJu3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def compute_jacobian(model, input_tensor):\n",
        "    \"\"\"\n",
        "    Compute the Jacobian matrix for a given model and input tensor.\n",
        "    Args:\n",
        "        model: The trained PyTorch model.\n",
        "        input_tensor: Input tensor for which to compute the Jacobian (requires gradient).\n",
        "    Returns:\n",
        "        Jacobian matrix as a torch tensor.\n",
        "    \"\"\"\n",
        "    # Enable gradient computation for the input\n",
        "    input_tensor = input_tensor.requires_grad_(True)\n",
        "\n",
        "    # Forward pass to compute model output\n",
        "    output = model(input_tensor)\n",
        "\n",
        "    # Create a Jacobian matrix initialized to zeros\n",
        "    jacobian = torch.zeros(output.size(0), input_tensor.size(0))  # Dynamically adjust size\n",
        "\n",
        "    # Compute partial derivatives for each output w.r.t each input\n",
        "    for i in range(output.size(0)):  # Iterate over each output dimension\n",
        "        grad = torch.autograd.grad(outputs=output[i], inputs=input_tensor,\n",
        "                                   retain_graph=True, create_graph=True)[0]\n",
        "        jacobian[i] = grad  # Store the gradient in the Jacobian matrix\n",
        "\n",
        "    return jacobian\n",
        "\n",
        "# Example input from the test set\n",
        "# Assuming X_test is already a PyTorch tensor; if not, convert it from NumPy\n",
        "# X_test[0] contains [j0, j1, cos(j0), cos(j1), sin(j0)]\n",
        "input_tensor = torch.tensor(X_test[0], dtype=torch.float32)\n",
        "\n",
        "# Compute the Jacobian using the model\n",
        "jacobian = compute_jacobian(model, input_tensor)\n",
        "print(f\"Jacobian for test input:\\n{jacobian}\")"
      ],
      "metadata": {
        "id": "qr65Re_IJxft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6435408a-2a6f-4bd3-8c2c-63cb7cbe8e40"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian for test input:\n",
            "tensor([[ 0.0265, -0.0118,  0.0359, -0.0367,  0.0810,  0.0478],\n",
            "        [-0.0282,  0.0346, -0.0076,  0.0057, -0.0221, -0.0183],\n",
            "        [ 0.2024,  0.1819,  0.1417,  0.0613,  0.0826, -0.0051],\n",
            "        [-0.0090,  0.0595, -0.1279, -0.3534,  0.3820,  0.3980]],\n",
            "       grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2. Compare the computed Jacobian with the analytical Jacobian for the 2-joint robot."
      ],
      "metadata": {
        "id": "rcFxsQjkJx1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Analytical Jacobian for a 2-DOF robot\n",
        "def analytical_jacobian_from_test(data):\n",
        "    # Extract joint angles from data\n",
        "    j0 = data[0]  # j0\n",
        "    j1 = data[1]  # j1\n",
        "    l1 = 1.0  # Link 1 length\n",
        "    l2 = 1.0  # Link 2 length\n",
        "\n",
        "    # Calculate the Jacobian elements using the analytical formula\n",
        "    J = np.array([\n",
        "        [-l1 * np.sin(j0) - l2 * np.sin(j0 + j1), -l2 * np.sin(j0 + j1)],\n",
        "        [l1 * np.cos(j0) + l2 * np.cos(j0 + j1), l2 * np.cos(j0 + j1)]\n",
        "    ])\n",
        "    return J\n",
        "\n",
        "# Example input from X_test[0]\n",
        "# j0, j1, cos(j0), cos(j1), sin(j0)\n",
        "X_test = X_test[0]\n",
        "# Compute analytical Jacobian\n",
        "J_analytical = analytical_jacobian_from_test(X_test_0)\n",
        "print(f\"Analytical Jacobian:\\n{J_analytical}\")"
      ],
      "metadata": {
        "id": "ZwQ2k3qMJ2Jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7b3501-79db-4951-f941-f9d480391878"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analytical Jacobian:\n",
            "[[-0.39535362 -0.29552021]\n",
            " [ 1.95034065  0.95533649]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwykRT0xjfp-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}