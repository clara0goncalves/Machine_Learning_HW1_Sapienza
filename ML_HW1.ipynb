{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install Dependecies"
      ],
      "metadata": {
        "id": "uYkosDKjN6-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "bA3-dNGdN6VD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1abb72-2859-4884-8cdc-0088c98a5916"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set device to GPU if is available otherwise set device as cpu**"
      ],
      "metadata": {
        "id": "83S06ig1RMKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check if GPU is available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "1IX6jLICPN4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3b95ed-90b8-4a37-b9a4-2f0db9f72164"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "BaBjTEuIRHsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.base import BaseEstimator, RegressorMixin"
      ],
      "metadata": {
        "id": "7jsLAS7jRJ2-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Dataset##\n",
        "\n",
        "- The Datatset used in this project was generated using the Mujoco simulator with three different configurations:\n",
        "- 2D (2 joints)\n",
        "- 2D (3 joints)\n",
        "- 3D (5 joints)\n",
        "\n",
        "The format of the data is in CSV format, including information about Joint angles, fingertip position, and orientation.\n"
      ],
      "metadata": {
        "id": "hIO0AeMWIExL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1. Visualise data from the simulator"
      ],
      "metadata": {
        "id": "0_uqRtyhJDj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler2.csv"
      ],
      "metadata": {
        "id": "6VflkHGKJDRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d930bbc8-7a70-49fd-c2e8-e34784319df5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j0;j1;cos(j0);cos(j1);sin(j0);sin(j1);ft_x;ft_y;ft_qw;ft_qz\n",
            " 0.055; -0.012;  0.998;  1.000;  0.055; -0.012;  0.210;  0.010;  1.000;  0.021\n",
            " 0.076; -0.017;  0.997;  1.000;  0.076; -0.017;  0.210;  0.014;  1.000;  0.030\n",
            " 0.148; -0.011;  0.989;  1.000;  0.147; -0.011;  0.208;  0.030;  0.998;  0.068\n",
            " 0.214;  0.048;  0.977;  0.999;  0.212;  0.048;  0.204;  0.050;  0.991;  0.131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler3.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNgZg0OJNaVV",
        "outputId": "452a692f-3de3-4689-e43b-873495805c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'logfiler3.csv' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler5.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm_lpt6_Nc-X",
        "outputId": "5ecbef36-fb82-4e42-e30e-3842dff2f658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'logfiler5.csv' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. Preprocess the data\n"
      ],
      "metadata": {
        "id": "rbfjJsgxJI80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2R Robot"
      ],
      "metadata": {
        "id": "aCM-EXuFQxkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dJxB_FilEapT"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('logfiler2.csv', delimiter=';')\n",
        "\n",
        "# Preprocessing: Extract inputs (joint angles and their trigonometric functions) and outputs (fingertip positions and quaternions)\n",
        "X = data[['j0', 'j1', 'cos(j0)', 'cos(j1)', 'sin(j0)', 'sin(j1)']].values\n",
        "y = data[['ft_x' ,'ft_y' ,'ft_qw','ft_qz']].values\n",
        "\n",
        "# Normalize input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Split the data into training and testing sets"
      ],
      "metadata": {
        "id": "a_UHnh5KJX6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training, validation, and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "jze3VIDOQ_aq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Train Forward Kinematics Models##\n",
        "\n"
      ],
      "metadata": {
        "id": "gcdL1pWYJNsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Robot 2R"
      ],
      "metadata": {
        "id": "LIaJ6J5pOJey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the architecture of the model (Feedforward Neural Network) to learn forward kinematics.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1yDUGGEzJSao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ForwardKinematicsModel(nn.Module):\n",
        "    def __init__(self, hidden_size, dropout_rate=0.3):\n",
        "        super(ForwardKinematicsModel, self).__init__()\n",
        "        # Define a feedforward network with configurable hidden_size and dropout\n",
        "        self.fc1 = nn.Linear(6, hidden_size)  # Input layer\n",
        "        self.dropout1 = nn.Dropout(p=dropout_rate)    # Dropout after first hidden layer\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Second hidden layer\n",
        "        self.dropout2 = nn.Dropout(p=dropout_rate)    # Dropout after second hidden layer\n",
        "        self.fc3 = nn.Linear(hidden_size, 4)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)  # Apply dropout after first hidden layer\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)  # Apply dropout after second hidden layer\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pwmiwxseZOMX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hyperparameter Search"
      ],
      "metadata": {
        "id": "mvZc8OBWPvSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Grid Search"
      ],
      "metadata": {
        "id": "kEHlC7SSNV8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Regressor Wrapper\n",
        "class PyTorchRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, hidden_size=hidden_size  , lr=learning_rate, epochs=num_epochs):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.model = ForwardKinematicsModel(hidden_size=self.hidden_size)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_train = torch.tensor(X, dtype=torch.float32)\n",
        "        y_train = torch.tensor(y, dtype=torch.float32)\n",
        "        for epoch in range(self.epochs):\n",
        "            self.model.train()\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(X_train)\n",
        "            loss = self.criterion(output, y_train)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_test = torch.tensor(X, dtype=torch.float32)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X_test)\n",
        "        return predictions.numpy()\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('logfiler2.csv', sep=';')\n",
        "X = df[['j0', 'j1', 'cos(j0)', 'cos(j1)', 'sin(j0)', 'sin(j1)']].values\n",
        "y = df[['ft_x' ,'ft_y' ,'ft_qw','ft_qz']].values\n",
        "\n",
        "# Split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up hyperparameters to search\n",
        "param_grid = {\n",
        "    'hidden_size': [32, 64, 128],  # Try different numbers of hidden units\n",
        "    'lr': [0.001, 0.01],           # Try different learning rates\n",
        "    'epochs': [100, 200],          # Try different numbers of epochs\n",
        "}\n",
        "\n",
        "# Instantiate the model wrapper\n",
        "pytorch_model = PyTorchRegressor()\n",
        "\n",
        "# Use GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=pytorch_model, param_grid=param_grid, cv=3, verbose=2, n_jobs=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best two combinations of hyperparameters\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "results = results.sort_values(by='mean_test_score', ascending=False)\n",
        "\n",
        "# Print the best and second-best hyperparameters\n",
        "print(\"Best combination of hyperparameters:\")\n",
        "print(results.iloc[0][['param_hidden_size', 'param_lr', 'param_epochs', 'mean_test_score']])\n",
        "print(\"\\nSecond-best combination of hyperparameters:\")\n",
        "print(results.iloc[1][['param_hidden_size', 'param_lr', 'param_epochs', 'mean_test_score']])\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_loss = mean_squared_error(y_test, y_pred)\n",
        "print(f\"\\nTest MSE of the best model: {test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "Rn7gU9ofNU9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1935b10a-c0c8-4b22-df6c-1ec234dbaed9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "[CV] END ...............epochs=100, hidden_size=32, lr=0.001; total time=   5.1s\n",
            "[CV] END ...............epochs=100, hidden_size=32, lr=0.001; total time=   4.8s\n",
            "[CV] END ...............epochs=100, hidden_size=32, lr=0.001; total time=   4.6s\n",
            "[CV] END ................epochs=100, hidden_size=32, lr=0.01; total time=   5.8s\n",
            "[CV] END ................epochs=100, hidden_size=32, lr=0.01; total time=   4.2s\n",
            "[CV] END ................epochs=100, hidden_size=32, lr=0.01; total time=   4.7s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   5.1s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   4.4s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   5.6s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   4.9s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   5.0s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   5.7s\n",
            "[CV] END ..............epochs=100, hidden_size=128, lr=0.001; total time=   5.3s\n",
            "[CV] END ..............epochs=100, hidden_size=128, lr=0.001; total time=   4.9s\n",
            "[CV] END ..............epochs=100, hidden_size=128, lr=0.001; total time=   4.9s\n",
            "[CV] END ...............epochs=100, hidden_size=128, lr=0.01; total time=   4.3s\n",
            "[CV] END ...............epochs=100, hidden_size=128, lr=0.01; total time=   4.5s\n",
            "[CV] END ...............epochs=100, hidden_size=128, lr=0.01; total time=   5.0s\n",
            "[CV] END ...............epochs=200, hidden_size=32, lr=0.001; total time=   8.7s\n",
            "[CV] END ...............epochs=200, hidden_size=32, lr=0.001; total time=   9.6s\n",
            "[CV] END ...............epochs=200, hidden_size=32, lr=0.001; total time=   9.4s\n",
            "[CV] END ................epochs=200, hidden_size=32, lr=0.01; total time=   8.8s\n",
            "[CV] END ................epochs=200, hidden_size=32, lr=0.01; total time=   9.2s\n",
            "[CV] END ................epochs=200, hidden_size=32, lr=0.01; total time=   9.5s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   8.7s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   9.3s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   9.5s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   8.8s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   9.2s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   9.4s\n",
            "[CV] END ..............epochs=200, hidden_size=128, lr=0.001; total time=  11.0s\n",
            "[CV] END ..............epochs=200, hidden_size=128, lr=0.001; total time=   8.7s\n",
            "[CV] END ..............epochs=200, hidden_size=128, lr=0.001; total time=  14.1s\n",
            "[CV] END ...............epochs=200, hidden_size=128, lr=0.01; total time=  10.0s\n",
            "[CV] END ...............epochs=200, hidden_size=128, lr=0.01; total time=  11.4s\n",
            "[CV] END ...............epochs=200, hidden_size=128, lr=0.01; total time=   9.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best combination of hyperparameters:\n",
            "param_hidden_size         128\n",
            "param_lr                0.001\n",
            "param_epochs              200\n",
            "mean_test_score      0.783651\n",
            "Name: 10, dtype: object\n",
            "\n",
            "Second-best combination of hyperparameters:\n",
            "param_hidden_size          32\n",
            "param_lr                0.001\n",
            "param_epochs              200\n",
            "mean_test_score      0.775462\n",
            "Name: 6, dtype: object\n",
            "\n",
            "Test MSE of the best model: 0.0146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model with the best 2 parameters found by grid search"
      ],
      "metadata": {
        "id": "g9ueGIvGPcCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train the models on joint angle inputs to predict fingertip positions."
      ],
      "metadata": {
        "id": "tDBMT_K2PiS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 128\n",
        "learning_rate = 0.001\n",
        "num_epochs = 200"
      ],
      "metadata": {
        "id": "fz1ipjrTwD-y"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the loss function and optimizer"
      ],
      "metadata": {
        "id": "Tio9LYtzPKFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ForwardKinematicsModel(hidden_size=hidden_size)"
      ],
      "metadata": {
        "id": "3xDtcCCFO-hb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "j8l_q3FnzxFk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors only if necessary\n",
        "X_train = X_train.clone().detach().float() if isinstance(X_train, torch.Tensor) else torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = y_train.clone().detach().float() if isinstance(y_train, torch.Tensor) else torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = X_val.clone().detach().float() if isinstance(X_val, torch.Tensor) else torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = y_val.clone().detach().float() if isinstance(y_val, torch.Tensor) else torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = X_test.clone().detach().float() if isinstance(X_test, torch.Tensor) else torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = y_test.clone().detach().float() if isinstance(y_test, torch.Tensor) else torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "szvcvhW6ylGh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables for early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 4\n",
        "no_improvement_epochs = 0\n",
        "best_model_path = \"best_model.pth\"  # Path to save the best model\n",
        "\n",
        "# Training loop with early stopping\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs, y_val)\n",
        "\n",
        "            # Calculate additional metrics\n",
        "            mae = mean_absolute_error(y_val.numpy(), val_outputs.numpy())\n",
        "            r2 = r2_score(y_val.numpy(), val_outputs.numpy())\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "                  f\"Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, \"\n",
        "                  f\"MAE: {mae:.4f}, R^2: {r2:.4f}\")\n",
        "\n",
        "            # Early stopping check\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                no_improvement_epochs = 0\n",
        "                # Save the best model\n",
        "                torch.save(model.state_dict(), best_model_path)\n",
        "                print(f\"Model saved at epoch {epoch+1} with Val Loss: {val_loss:.4f}\")\n",
        "            else:\n",
        "                no_improvement_epochs += 1\n",
        "\n",
        "            if no_improvement_epochs >= patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}. Best Val Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        model.train()  # Switch back to training mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxXXl4lG5FQh",
        "outputId": "9ed62447-b040-42e7-abf8-761c84de442e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/200], Train Loss: 0.1243, Val Loss: 0.1280, MAE: 0.2530, R^2: 0.2904\n",
            "Model saved at epoch 10 with Val Loss: 0.1280\n",
            "Epoch [20/200], Train Loss: 0.0694, Val Loss: 0.0811, MAE: 0.2091, R^2: 0.3298\n",
            "Model saved at epoch 20 with Val Loss: 0.0811\n",
            "Epoch [30/200], Train Loss: 0.0477, Val Loss: 0.0713, MAE: 0.1911, R^2: 0.4968\n",
            "Model saved at epoch 30 with Val Loss: 0.0713\n",
            "Epoch [40/200], Train Loss: 0.0344, Val Loss: 0.0691, MAE: 0.1867, R^2: 0.5137\n",
            "Model saved at epoch 40 with Val Loss: 0.0691\n",
            "Epoch [50/200], Train Loss: 0.0290, Val Loss: 0.0674, MAE: 0.1790, R^2: 0.6052\n",
            "Model saved at epoch 50 with Val Loss: 0.0674\n",
            "Epoch [60/200], Train Loss: 0.0259, Val Loss: 0.0616, MAE: 0.1686, R^2: 0.6574\n",
            "Model saved at epoch 60 with Val Loss: 0.0616\n",
            "Epoch [70/200], Train Loss: 0.0234, Val Loss: 0.0631, MAE: 0.1706, R^2: 0.6372\n",
            "Epoch [80/200], Train Loss: 0.0218, Val Loss: 0.0654, MAE: 0.1745, R^2: 0.6237\n",
            "Epoch [90/200], Train Loss: 0.0205, Val Loss: 0.0655, MAE: 0.1748, R^2: 0.6323\n",
            "Epoch [100/200], Train Loss: 0.0195, Val Loss: 0.0648, MAE: 0.1733, R^2: 0.6459\n",
            "Early stopping triggered at epoch 100. Best Val Loss: 0.0616\n",
            "Epoch [110/200], Train Loss: 0.0185, Val Loss: 0.0645, MAE: 0.1729, R^2: 0.6512\n",
            "Early stopping triggered at epoch 110. Best Val Loss: 0.0616\n",
            "Epoch [120/200], Train Loss: 0.0177, Val Loss: 0.0645, MAE: 0.1728, R^2: 0.6549\n",
            "Early stopping triggered at epoch 120. Best Val Loss: 0.0616\n",
            "Epoch [130/200], Train Loss: 0.0172, Val Loss: 0.0641, MAE: 0.1721, R^2: 0.6575\n",
            "Early stopping triggered at epoch 130. Best Val Loss: 0.0616\n",
            "Epoch [140/200], Train Loss: 0.0166, Val Loss: 0.0638, MAE: 0.1716, R^2: 0.6602\n",
            "Early stopping triggered at epoch 140. Best Val Loss: 0.0616\n",
            "Epoch [150/200], Train Loss: 0.0161, Val Loss: 0.0635, MAE: 0.1709, R^2: 0.6638\n",
            "Early stopping triggered at epoch 150. Best Val Loss: 0.0616\n",
            "Epoch [160/200], Train Loss: 0.0158, Val Loss: 0.0633, MAE: 0.1706, R^2: 0.6655\n",
            "Early stopping triggered at epoch 160. Best Val Loss: 0.0616\n",
            "Epoch [170/200], Train Loss: 0.0153, Val Loss: 0.0630, MAE: 0.1698, R^2: 0.6672\n",
            "Early stopping triggered at epoch 170. Best Val Loss: 0.0616\n",
            "Epoch [180/200], Train Loss: 0.0150, Val Loss: 0.0627, MAE: 0.1693, R^2: 0.6691\n",
            "Early stopping triggered at epoch 180. Best Val Loss: 0.0616\n",
            "Epoch [190/200], Train Loss: 0.0147, Val Loss: 0.0623, MAE: 0.1686, R^2: 0.6706\n",
            "Early stopping triggered at epoch 190. Best Val Loss: 0.0616\n",
            "Epoch [200/200], Train Loss: 0.0143, Val Loss: 0.0620, MAE: 0.1679, R^2: 0.6733\n",
            "Early stopping triggered at epoch 200. Best Val Loss: 0.0616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, y_test)\n",
        "    mae_test = mean_absolute_error(y_test.numpy(), test_outputs.numpy())\n",
        "    r2_test = r2_score(y_test.numpy(), test_outputs.numpy())\n",
        "\n",
        "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "    print(f\"Test MAE: {mae_test:.4f}\")\n",
        "    print(f\"Test R^2: {r2_test:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXuwFfNlkmEQ",
        "outputId": "ad419ebf-1722-4bfe-aa58-6688ae002326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0041\n",
            "Test MAE: 0.0505\n",
            "Test R^2: 0.5014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Compare Jacobians##\n"
      ],
      "metadata": {
        "id": "lWNe5FjVJolV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3.1. Compute the Jacobian matrix for the learned forward kinematics using automatic differentiation.\n",
        "\n"
      ],
      "metadata": {
        "id": "xTzh1e1BJu3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data (replace this with your actual dataset loading method)\n",
        "df = pd.read_csv('logfiler2.csv', sep=';')\n",
        "X = df[['j0', 'j1']].values  # Joint angles\n",
        "y = df[['ft_x', 'ft_y']].values  # Fingertip positions\n",
        "\n",
        "# Convert to torch tensor\n",
        "X_test = torch.tensor(X, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "vWgtFZP5OCJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_test is a tensor and you want to extract the first sample\n",
        "X_test_sample = X_test[0].clone().detach().unsqueeze(0).float()  # Add batch dimension and detach\n",
        "print(X_test_sample)"
      ],
      "metadata": {
        "id": "wXM9zpl2OMPJ",
        "outputId": "f1c677c0-dd42-4aad-ec04-d7bf1fd58d10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-3.0970, -2.6260, -0.9990, -0.8700, -0.0450, -0.4930]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model after training\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "print(\"Best model loaded for further evaluation or inference.\")"
      ],
      "metadata": {
        "id": "iqxhWP_UQORR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_2x2_jacobian(model, inputs):\n",
        "    # Ensure input gradients are enabled\n",
        "    if not inputs.requires_grad:\n",
        "        inputs.requires_grad = True\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # Select outputs of interest\n",
        "    ft_x, ft_y = outputs[0], outputs[1]\n",
        "    print(\"ft_x:\", ft_x)\n",
        "    print(\"ft_y:\", ft_y)\n",
        "\n",
        "    # Initialize the 2x2 Jacobian matrix\n",
        "    jacobian = torch.zeros(2, 2)\n",
        "\n",
        "    # Compute gradients for ft_x\n",
        "    grad_ft_x = torch.autograd.grad(ft_x, inputs, retain_graph=True, create_graph=True)[0]\n",
        "    jacobian[0, 0] = grad_ft_x[0]  # ∂ft_x/∂j0\n",
        "    jacobian[0, 1] = grad_ft_x[1]  # ∂ft_x/∂j1\n",
        "\n",
        "    # Compute gradients for ft_y\n",
        "    grad_ft_y = torch.autograd.grad(ft_y, inputs, retain_graph=True, create_graph=True)[0]\n",
        "    jacobian[1, 0] = grad_ft_y[0]  # ∂ft_y/∂j0\n",
        "    jacobian[1, 1] = grad_ft_y[1]  # ∂ft_y/∂j1\n",
        "\n",
        "    return jacobian"
      ],
      "metadata": {
        "id": "yNbeiZ1mRJRk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2. Compare the computed Jacobian with the analytical Jacobian for the 2-joint robot."
      ],
      "metadata": {
        "id": "rcFxsQjkJx1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Analytical Jacobian for a 2-DOF robot\n",
        "def analytical_jacobian_from_test(data):\n",
        "    # Extract joint angles from data\n",
        "    j0 = data[0]  # j0\n",
        "    j1 = data[1]  # j1\n",
        "\n",
        "    l1 = 1.0  # Link 1 length\n",
        "    l2 = 1.0  # Link 2 length\n",
        "\n",
        "    # Calculate the Jacobian elements using the analytical formula\n",
        "    J = np.array([\n",
        "        [-l1 * np.sin(j0) - l2 * np.sin(j0 + j1), -l2 * np.sin(j0 + j1)],\n",
        "        [l1 * np.cos(j0) + l2 * np.cos(j0 + j1), l2 * np.cos(j0 + j1)]\n",
        "    ])\n",
        "    return J"
      ],
      "metadata": {
        "id": "ZwQ2k3qMJ2Jp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "#Numerical Jacobian (calculated by FK_Jacobian)\n",
        "X_test_sample = torch.tensor([-3.0970, -2.6260, -0.9990, -0.8700, -0.0450, -0.4930], requires_grad=True)\n",
        "jacobian_numerical = compute_2x2_jacobian(model, X_test_sample)\n",
        "\n",
        "# Analytical Jacobian (calculated using analytical formula)X_test_sample = [-3.0970, -2.6260, -0.9990, -0.8700, -0.0450, -0.4930] # Extract joint angles for comparison\n",
        "X_test_sample = X_test_sample.detach().numpy()\n",
        "J_analytical = analytical_jacobian_from_test(X_test_sample)\n",
        "\n",
        "# Print both Jacobians\n",
        "print(\"Numerical Jacobian (PyTorch):\\n\", jacobian_numerical)\n",
        "print(\"Analytical Jacobian (2-DOF Robot):\\n\", J_analytical)\n",
        "\n",
        "# Compare both Jacobians by calculating the difference\n",
        "jacobian_difference = (jacobian_numerical.detach().numpy() - J_analytical)\n",
        "print(\"Difference between Numerical and Analytical Jacobians:\\n\", jacobian_difference)"
      ],
      "metadata": {
        "id": "uopqI4FVOPVR",
        "outputId": "e729fc06-e8aa-40ba-add9-4c51a6b3223f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical Jacobian (PyTorch):\n",
            " tensor([[ 0.0068, -0.0159],\n",
            "        [ 0.0118, -0.0285]], grad_fn=<CopySlices>)\n",
            "Analytical Jacobian (2-DOF Robot):\n",
            " [[-0.48676559 -0.53134358]\n",
            " [-0.15184945  0.84715647]]\n",
            "Difference between Numerical and Analytical Jacobians:\n",
            " [[ 0.49353678  0.51546606]\n",
            " [ 0.16368002 -0.8756997 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OcXMDYgJb2Dw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}