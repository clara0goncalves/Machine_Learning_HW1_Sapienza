{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install Dependecies"
      ],
      "metadata": {
        "id": "uYkosDKjN6-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "bA3-dNGdN6VD",
        "outputId": "bbfbb14e-c01a-48c4-8cd0-68b4c13d2c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting sympy (from torch)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx (from torch)\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (3.1.2)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m381.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch)\n",
            "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filelock-3.16.1 fsspec-2024.10.0 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0 typing-extensions-4.12.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set device to GPU if is available otherwise set device as cpu**"
      ],
      "metadata": {
        "id": "83S06ig1RMKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check if GPU is available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "1IX6jLICPN4c",
        "outputId": "bfbe6b5a-e813-43ea-f6e7-49a574669e09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "BaBjTEuIRHsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "7jsLAS7jRJ2-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Dataset##\n",
        "\n",
        "- The Datatset used in this project was generated using the Mujoco simulator with three different configurations:\n",
        "- 2D (2 joints)\n",
        "- 2D (3 joints)\n",
        "- 3D (5 joints)\n",
        "\n",
        "The format of the data is in CSV format, including information about Joint angles, fingertip position, and orientation.\n"
      ],
      "metadata": {
        "id": "hIO0AeMWIExL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1. Visualise data from the simulator"
      ],
      "metadata": {
        "id": "0_uqRtyhJDj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler2.csv"
      ],
      "metadata": {
        "id": "6VflkHGKJDRC",
        "outputId": "5d2e905e-8fce-4afb-8097-84f371038339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j0;j1;cos(j0);cos(j1);sin(j0);sin(j1);ft_x;ft_y;ft_qw;ft_qz\r\n",
            " 0.055; -0.012;  0.998;  1.000;  0.055; -0.012;  0.210;  0.010;  1.000;  0.021\r\n",
            " 0.076; -0.017;  0.997;  1.000;  0.076; -0.017;  0.210;  0.014;  1.000;  0.030\r\n",
            " 0.148; -0.011;  0.989;  1.000;  0.147; -0.011;  0.208;  0.030;  0.998;  0.068\r\n",
            " 0.214;  0.048;  0.977;  0.999;  0.212;  0.048;  0.204;  0.050;  0.991;  0.131\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler3.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNgZg0OJNaVV",
        "outputId": "ff24ddc0-a8af-4804-e97c-a0add4288be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j0;j1;j2;cos(j0);cos(j1);cos(j2);sin(j0);sin(j1);sin(j2);ft_x;ft_y;ft_qw;ft_qz\r\n",
            " 0.055; -0.012;  0.072;  0.998;  1.000;  0.997;  0.055; -0.012;  0.072;  0.309;  0.022;  0.998;  0.057\r\n",
            " 0.076; -0.017;  0.100;  0.997;  1.000;  0.995;  0.076; -0.017;  0.100;  0.308;  0.031;  0.997;  0.080\r\n",
            " 0.135; -0.059;  0.194;  0.991;  0.998;  0.981;  0.135; -0.059;  0.193;  0.305;  0.050;  0.991;  0.135\r\n",
            " 0.228; -0.110;  0.295;  0.974;  0.994;  0.957;  0.226; -0.109;  0.290;  0.297;  0.079;  0.979;  0.205\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 logfiler5.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm_lpt6_Nc-X",
        "outputId": "c35fef0c-66e5-4c1a-ee7e-db3d1cb989b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "j0;j1;j2;j3;j4;cos(j0);cos(j1);cos(j2);cos(j3);cos(j4);sin(j0);sin(j1);sin(j2);sin(j3);sin(j4);ft_x;ft_y;ft_z;ft_qw;ft_qx;ft_qy;ft_qz\r\n",
            " 0.000;  0.000;  0.000;  0.000;  0.000;  1.000;  1.000;  1.000;  1.000;  1.000;  0.000;  0.000;  0.000;  0.000;  0.000;  0.000;  0.000;  0.590;  1.000;  0.000;  0.000;  0.000\r\n",
            " 0.022; -0.005;  0.028;  0.016; -0.032;  1.000;  1.000;  1.000;  1.000;  0.999;  0.022; -0.005;  0.028;  0.016; -0.032;  0.011;  0.004;  0.590;  1.000; -0.016;  0.019;  0.011\r\n",
            " 0.103;  0.005;  0.107;  0.017; -0.100;  0.995;  1.000;  0.994;  1.000;  0.995;  0.102;  0.005;  0.106;  0.017; -0.099;  0.041;  0.016;  0.587;  0.995; -0.053;  0.061;  0.054\r\n",
            " 0.209;  0.067;  0.216;  0.013; -0.174;  0.978;  0.998;  0.977;  1.000;  0.985;  0.208;  0.067;  0.215;  0.013; -0.173;  0.100;  0.042;  0.573;  0.979; -0.101;  0.138;  0.116\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. Preprocess the data\n"
      ],
      "metadata": {
        "id": "rbfjJsgxJI80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2R Robot"
      ],
      "metadata": {
        "id": "aCM-EXuFQxkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dJxB_FilEapT"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('logfiler2.csv', delimiter=';')\n",
        "\n",
        "# Preprocessing: Extract inputs (joint angles and their trigonometric functions) and outputs (fingertip positions and quaternions)\n",
        "X = data[['j0', 'j1', 'cos(j0)', 'cos(j1)', 'sin(j0)', 'sin(j1)']].values\n",
        "y = data[['ft_x', 'ft_y', 'ft_qw', 'ft_qz']].values\n",
        "\n",
        "# Normalize input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Split the data into training and testing sets"
      ],
      "metadata": {
        "id": "a_UHnh5KJX6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training, validation, and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "jze3VIDOQ_aq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Train Forward Kinematics Models##\n",
        "\n"
      ],
      "metadata": {
        "id": "gcdL1pWYJNsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Robot 2R"
      ],
      "metadata": {
        "id": "LIaJ6J5pOJey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the architecture of the model (Feedforward Neural Network) to learn forward kinematics.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1yDUGGEzJSao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the loss function and optimizer"
      ],
      "metadata": {
        "id": "Tio9LYtzPKFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Neural Network model\n",
        "class ForwardKinematicsModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ForwardKinematicsModel, self).__init__()\n",
        "        # Define a simple feedforward network with 2 hidden layers\n",
        "        self.fc1 = nn.Linear(6, 64)  # Input layer (2 joint angles)\n",
        "        self.fc2 = nn.Linear(64, 64) # Hidden layer\n",
        "        self.fc3 = nn.Linear(64, 4)  # Output layer (fingertip position)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "model = ForwardKinematicsModel()"
      ],
      "metadata": {
        "id": "cxTQNHySMQM1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer"
      ],
      "metadata": {
        "id": "UNRXEMjTMZwk"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train the models on joint angle inputs to predict fingertip positions."
      ],
      "metadata": {
        "id": "tDBMT_K2PiS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train.float())\n",
        "    loss = criterion(outputs, y_train.float())\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    loss.backward()        # Backpropagation\n",
        "    optimizer.step()       # Update model parameters\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "5zgJJF00Mukv",
        "outputId": "79b1361b-33d9-40ad-9a84-9ae7e7b632df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.2598\n",
            "Epoch [200/1000], Loss: 0.2598\n",
            "Epoch [300/1000], Loss: 0.2598\n",
            "Epoch [400/1000], Loss: 0.2598\n",
            "Epoch [500/1000], Loss: 0.2598\n",
            "Epoch [600/1000], Loss: 0.2598\n",
            "Epoch [700/1000], Loss: 0.2598\n",
            "Epoch [800/1000], Loss: 0.2598\n",
            "Epoch [900/1000], Loss: 0.2598\n",
            "Epoch [1000/1000], Loss: 0.2598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs, y_val)\n",
        "\n",
        "            # Calculate additional metrics\n",
        "            mae = mean_absolute_error(y_val.numpy(), val_outputs.numpy())\n",
        "            r2 = r2_score(y_val.numpy(), val_outputs.numpy())\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "                  f\"Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, \"\n",
        "                  f\"MAE: {mae:.4f}, R^2: {r2:.4f}\")\n",
        "        model.train()  # Switch back to training mode\n"
      ],
      "metadata": {
        "id": "y_D8Hl3qkkjX",
        "outputId": "10414734-f35d-437b-8e49-135029442c5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0042, R^2: 0.9991\n",
            "Epoch [200/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0034, R^2: 0.9994\n",
            "Epoch [300/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0030, R^2: 0.9995\n",
            "Epoch [400/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0028, R^2: 0.9996\n",
            "Epoch [500/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0025, R^2: 0.9996\n",
            "Epoch [600/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0024, R^2: 0.9997\n",
            "Epoch [700/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0022, R^2: 0.9997\n",
            "Epoch [800/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0022, R^2: 0.9997\n",
            "Epoch [900/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0021, R^2: 0.9997\n",
            "Epoch [1000/1000], Train Loss: 0.0000, Val Loss: 0.0000, MAE: 0.0020, R^2: 0.9998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, y_test)\n",
        "    mae_test = mean_absolute_error(y_test.numpy(), test_outputs.numpy())\n",
        "    r2_test = r2_score(y_test.numpy(), test_outputs.numpy())\n",
        "\n",
        "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "    print(f\"Test MAE: {mae_test:.4f}\")\n",
        "    print(f\"Test R^2: {r2_test:.4f}\")\n"
      ],
      "metadata": {
        "id": "lXuwFfNlkmEQ",
        "outputId": "dccca0ef-6564-4ae6-cb9c-c407bf0eaf76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0000\n",
            "Test MAE: 0.0020\n",
            "Test R^2: 0.9998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():  # No need to calculate gradients during inference\n",
        "    predictions = model(X_test.float())\n",
        "    test_loss = criterion(predictions, y_test.float())\n",
        "    print(f\"Test Loss: {test_loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "57ezVRl1Mw13",
        "outputId": "750e2994-e3ce-4f9c-8105-4930543a020a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hyperparameter Search"
      ],
      "metadata": {
        "id": "mvZc8OBWPvSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.001, 0.01]\n",
        "hidden_layer_sizes = [64, 128]\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_params = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for size in hidden_layer_sizes:\n",
        "        # Define the model with new parameters\n",
        "        model = ForwardKinematicsModel()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        # Train the model for a few epochs (for hyperparameter tuning)\n",
        "        for epoch in range(100):\n",
        "            model.train()\n",
        "            outputs = model(X_train.float())\n",
        "            loss = criterion(outputs, y_train.float())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluate the model\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = model(X_test.float())\n",
        "            test_loss = criterion(predictions, y_test.float())\n",
        "\n",
        "        # Store the best parameters\n",
        "        if test_loss.item() < best_loss:\n",
        "            best_loss = test_loss.item()\n",
        "            best_params = {'lr': lr, 'hidden_size': size}\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}, Loss: {best_loss}\")"
      ],
      "metadata": {
        "id": "UcKOC1GGMzvT",
        "outputId": "e9a511eb-6305-4920-b1d4-1269c15b8c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'lr': 0.01, 'hidden_size': 128}, Loss: 0.00011883940169354901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Grid Se"
      ],
      "metadata": {
        "id": "kEHlC7SSNV8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "# Define the Forward Kinematics Neural Network Model\n",
        "class ForwardKinematicsModel(nn.Module):\n",
        "    def __init__(self, hidden_size=64):\n",
        "        super(ForwardKinematicsModel, self).__init__()\n",
        "        # Define the network with flexible hidden layer size\n",
        "        self.fc1 = nn.Linear(6, hidden_size)  # Input layer (2 joint angles)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Hidden layer\n",
        "        self.fc3 = nn.Linear(hidden_size, 4)  # Output layer (fingertip position)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Wrapper class for PyTorch model to use with scikit-learn GridSearchCV\n",
        "class PyTorchRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, hidden_size=64, lr=0.001, epochs=100):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.model = ForwardKinematicsModel(hidden_size=self.hidden_size)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Convert data to torch tensors\n",
        "        X_train = torch.tensor(X, dtype=torch.float32)\n",
        "        y_train = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(self.epochs):\n",
        "            self.model.train()\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(X_train)\n",
        "            loss = self.criterion(output, y_train)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Convert data to torch tensor and return predictions\n",
        "        X_test = torch.tensor(X, dtype=torch.float32)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(X_test)\n",
        "        return predictions.numpy()\n",
        "\n",
        "# Load your dataset (replace this with your actual dataset)\n",
        "df = pd.read_csv('logfiler2.csv', sep=';')\n",
        "X = df[['j0', 'j1']].values  # Joint angles\n",
        "y = df[['ft_x', 'ft_y']].values  # Fingertip positions\n",
        "\n",
        "# Split dataset into training and test sets (80/20 split)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up hyperparameters to search\n",
        "param_grid = {\n",
        "    'hidden_size': [64, 128],       # Number of hidden units in the hidden layers\n",
        "    'lr': [0.001, 0.01],            # Learning rates\n",
        "    'epochs': [100, 200],           # Number of epochs to train\n",
        "}\n",
        "\n",
        "# Instantiate the PyTorch model wrapper for GridSearchCV\n",
        "pytorch_model = PyTorchRegressor()\n",
        "\n",
        "# Use GridSearchCV with the model wrapper\n",
        "grid_search = GridSearchCV(estimator=pytorch_model, param_grid=param_grid, cv=3, verbose=2, n_jobs=1)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_loss = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Test MSE: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "Rn7gU9ofNU9l",
        "outputId": "4cdb6ad0-890b-4ab5-e2e0-7b3ac05746ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=100, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ..............epochs=100, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ..............epochs=100, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ..............epochs=100, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=100, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=64, lr=0.001; total time=   0.0s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ................epochs=200, hidden_size=64, lr=0.01; total time=   0.0s\n",
            "[CV] END ..............epochs=200, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ..............epochs=200, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ..............epochs=200, hidden_size=128, lr=0.001; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=128, lr=0.01; total time=   0.0s\n",
            "[CV] END ...............epochs=200, hidden_size=128, lr=0.01; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n16 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_31/2599139597.py\", line 44, in fit\n    output = self.model(X_train)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_31/2599139597.py\", line 20, in forward\n    x = torch.relu(self.fc1(x))\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (53333x2 and 6x64)\n\n--------------------------------------------------------------------------------\n8 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_31/2599139597.py\", line 44, in fit\n    output = self.model(X_train)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_31/2599139597.py\", line 20, in forward\n    x = torch.relu(self.fc1(x))\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (53334x2 and 6x64)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[64], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mpytorch_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Perform the grid search\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters and the best model\u001b[39;00m\n\u001b[1;32m     85\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n16 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_31/2599139597.py\", line 44, in fit\n    output = self.model(X_train)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_31/2599139597.py\", line 20, in forward\n    x = torch.relu(self.fc1(x))\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (53333x2 and 6x64)\n\n--------------------------------------------------------------------------------\n8 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_31/2599139597.py\", line 44, in fit\n    output = self.model(X_train)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_31/2599139597.py\", line 20, in forward\n    x = torch.relu(self.fc1(x))\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (53334x2 and 6x64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Compare Jacobians##\n"
      ],
      "metadata": {
        "id": "lWNe5FjVJolV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3.1. Compute the Jacobian matrix for the learned forward kinematics using automatic differentiation.\n",
        "\n"
      ],
      "metadata": {
        "id": "xTzh1e1BJu3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_jacobian(model, input_tensor):\n",
        "    # Use PyTorch's autograd to compute the Jacobian\n",
        "    input_tensor = input_tensor.requires_grad_(True)\n",
        "    output = model(input_tensor)\n",
        "\n",
        "    # Compute Jacobian matrix (2x2 for 2 DOF robot)\n",
        "    jacobian = torch.zeros(2, 2)\n",
        "    for i in range(2):\n",
        "        jacobian[i] = torch.autograd.grad(output[i], input_tensor, retain_graph=True)[0]\n",
        "    return jacobian\n",
        "\n",
        "# Example input (joint angles)\n",
        "input_tensor = torch.tensor([0.1, 0.2])  # Example joint angles (2 DOF)\n",
        "jacobian = compute_jacobian(model, input_tensor)\n",
        "print(f\"Jacobian:\\n{jacobian}\")\n"
      ],
      "metadata": {
        "id": "qr65Re_IJxft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2. Compare the computed Jacobian with the analytical Jacobian for the 2-joint robot."
      ],
      "metadata": {
        "id": "rcFxsQjkJx1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Analytical Jacobian for 2-DOF robot (example)\n",
        "def analytical_jacobian(theta):\n",
        "    # This is an example, replace with the actual robot's kinematic equations\n",
        "    # Here we assume a simple 2 DOF manipulator with planar joints\n",
        "    J = np.array([[-np.sin(theta[0]) - np.sin(theta[0] + theta[1]), -np.sin(theta[0] + theta[1])],\n",
        "                  [np.cos(theta[0]) + np.cos(theta[0] + theta[1]), np.cos(theta[0] + theta[1])]])\n",
        "    return J\n",
        "\n",
        "# Compute analytical Jacobian for a specific input\n",
        "theta = [0.1, 0.2]\n",
        "J_analytical = analytical_jacobian(theta)\n",
        "print(f\"Analytical Jacobian:\\n{J_analytical}\")\n",
        "\n",
        "# Compare the learned Jacobian with the analytical Jacobian\n",
        "# Convert learned Jacobian (from PyTorch) to a numpy array for comparison\n",
        "J_learned = jacobian.detach().numpy()\n",
        "\n",
        "# Compute the difference\n",
        "jacobian_diff = np.linalg.norm(J_analytical - J_learned)\n",
        "print(f\"Difference between Analytical and Learned Jacobian: {jacobian_diff:.4f}\")\n"
      ],
      "metadata": {
        "id": "ZwQ2k3qMJ2Jp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}